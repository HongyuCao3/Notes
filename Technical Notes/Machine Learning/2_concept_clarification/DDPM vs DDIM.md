# DDPM vs DDIM — A Structured Note

## 1. Full Names

- **DDPM**: *Denoising Diffusion Probabilistic Model*
- **DDIM**: *Denoising Diffusion Implicit Model*

Key distinction from the names:
- **Probabilistic** → explicit conditional probability and stochastic sampling
- **Implicit** → no explicit conditional density, deterministic or semi-stochastic mapping

---

## 2. Shared Setup (Training & Forward Process)

Both DDPM and DDIM typically share the same **training objective** and **forward diffusion process**.

### Forward Diffusion (Noise Adding)
Given clean data $x_0$:

$x_t = \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$

Where:
- $t \in \{1, \dots, T\}$: diffusion timestep
- $\alpha_t = 1 - \beta_t$
- $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$
- $\beta_t$: noise schedule

### Neural Network Objective
The model is trained to predict noise:

$\epsilon_\theta(x_t, t) \approx \epsilon$

---

## 3. Reconstructing the Clean Image Estimate

A key shared intermediate quantity is the predicted clean image:

$\hat{x}_0(x_t, t)
= \frac{x_t - \sqrt{1 - \bar{\alpha}_t} \, \epsilon_\theta(x_t, t)} {\sqrt{\bar{\alpha}_t}}$

**Intuition**:
- If the model correctly predicts the noise in $x_t$,
  we can algebraically recover an estimate of the original image $x_0$.

---

## 4. DDPM: Probabilistic Reverse Process

### Reverse Distribution
DDPM explicitly models a conditional probability:

$p_\theta(x_{t-1} \mid x_t) = \mathcal{N}\bigl(\mu_\theta(x_t, t), \Sigma_t\bigr)$

Sampling step:

$x_{t-1} = \mu_\theta(x_t, t) + \sigma_t z, \quad z \sim \mathcal{N}(0, I)$

Where:
- $\mu_\theta$: mean derived from $\epsilon_\theta$
- $\sigma_t^2 = \Sigma_t$: predefined or learned variance

### Characteristics
- Explicit probability model
- Markovian reverse process
- Random noise injected at **every step**
- High sample diversity
- Slower sampling (typically requires many steps)

**Mental model**:
> DDPM rolls a dice at every reverse step.

---

## 5. DDIM: Implicit Reverse Process

DDIM defines a **non-Markovian implicit mapping** instead of sampling from an explicit distribution.

### Deterministic DDIM Update ($\eta = 0$)

$x_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \, \hat{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1}} \, \epsilon_\theta(x_t, t)$

Where:
- $\hat{x}_0$ is computed from the current $x_t$
- No additional noise is sampled

### Semi-Stochastic DDIM ($\eta \in [0,1]$)

Define variance term:

$\sigma_t
= \eta \cdot \sqrt{\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t}} \cdot \sqrt{1 - \frac{\bar{\alpha}_t}{\bar{\alpha}_{t-1}}}$

Update rule:

$x_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \, \hat{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2}, \epsilon_\theta(x_t, t) + \sigma_t z, \quad z \sim \mathcal{N}(0, I)$

### Characteristics
- No explicit conditional density $p(x_{t-1} \mid x_t)$
- Deterministic when $\eta = 0$
- Non-Markovian
- Supports fast sampling with fewer steps
- Enables inversion (image → latent → image)

**Mental model**:
> DDIM follows a predefined trajectory instead of sampling a distribution.

---

## 6. Why DDIM Is Called “Implicit”

The term **implicit** means:
- The model does **not** define an explicit probability density
- Samples are generated by a transformation rule
- Density may be intractable or undefined

This is similar in spirit to:
- GANs (implicit generative models)
- ODE-based generative flows (deterministic trajectories)

In DDIM:
- The generative process is defined by equations, not distributions
- The reverse path can be deterministic and invertible

---

## 7. Practical Comparison

| Aspect | DDPM | DDIM |
|-----|-----|-----|
| Full name | Probabilistic Model | Implicit Model |
| Reverse step | Sample from Gaussian | Deterministic / semi-random mapping |
| Randomness | Always | Optional ($\eta$) |
| Markov property | Yes | No |
| Sampling speed | Slow | Fast |
| Sample diversity | High | Lower (unless $\eta > 0$) |
| Inversion support | No | Yes |

---

## 8. Engineering Insight

- **Training**: Usually DDPM-style (same network for both)
- **Sampling**: DDIM replaces the sampler, not the model
- **Scheduler**: Important, but insufficient alone — the update equation changes
- **Common usage**:
  - Train with DDPM
  - Sample with DDIM for speed and controllability

---

## 9. One-Sentence Summary

> **DDPM** generates samples by repeatedly sampling from explicit conditional distributions,  
> while **DDIM** generates samples by following an implicit (possibly deterministic) denoising trajectory defined by the same trained network.

---
